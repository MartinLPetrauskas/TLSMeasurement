#! /usr/bin/env python3

import concurrent.futures
import ssllabsscanner
import time
import random
import csv
import click
import requests
import subprocess

fieldnames = ['host', 'rank', 'industry', 'geoLocation', 'ipAddress', 'grade', 'protocols', 'vulnBeast',
              'supportsRc4', 'heartbleed', 'heartbeat', 'openSslCcs', 'openSSLLuckyMinus20', 'ticketbleed',
              'bleichenbacher', 'zombiePoodle', 'goldenDoodle', 'zeroLengthPaddingOracle', 'sleepingPoodle',
              'poodle', 'poodleTls', 'fallbackScsv', 'freak', 'logjam', 'drownVulnerable']


# CSV FIELD NAMES:
# - host
# - rank
# - industry (initially set to NA)
# - geo-location (initially set to NA)
# - ipAddress
# - grade
# - protocols
# - vulnBeast
# - supportsRc4
# - heartbleed
# - heartbeat
# - openSslCcs
# - openSSLLuckyMinus20
# - ticketbleed
# - bleichenbacher
# - zombiePoodle
# - goldenDoodle
# - zeroLengthPaddingOracle
# - sleepingPoodle
# - poodle
# - poodleTls
# - fallbackScsv
# - freak
# - logjam
# - drownVulnerable


def get_geolocation(host):
    """
    This function will get the GeoLocation of the given host
    :param host: hostname (i.e. example.com)
    :return: String with the properly formatted country (i.e. US, United States)
    """
    out = subprocess.Popen(['geoiplookup', host], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = out.communicate()
    country = stdout.decode('utf-8').split(': ')[1].rstrip()
    if 'can\'t resolve hostname' in country:
        return None
    else:
        return country


def scanning_func(url):
    wait = random.randint(0, 300)
    time.sleep(wait)
    try:
        response = requests.get('https://api.ssllabs.com/api/v3/info')
        response_data = response.json()
    except:
        a = scanning_func(url)
        return a
    availableAssessments = response_data['maxAssessments'] - response_data['currentAssessments']
    if availableAssessments <= 1:
        a = scanning_func(url)
        return a

    url_rank = url.split(',')
    print('STARTING TLS SCAN FOR: ' + url_rank[1])
    data = ssllabsscanner.scan(url_rank[1], True)

    if 'errors' in data.keys():
        print(data)
        a = scanning_func(url)
        return a

    try:
        host = data['host']
    except:
        host = 'NA'
    try:
        rank = url_rank[0]
    except:
        rank = 'NA'
    industry = 'NA'

    try:
        geoLocation = get_geolocation(host)
    except:
        geoLocation = 'NA'

    try:
        ipAddress = data['endpoints'][0]['ipAddress']
    except:
        ipAddress = 'NA'

    try:
        grade = data['endpoints'][0]['gradeTrustIgnored']
    except:
        grade = 'NA'

    try:
        protocols = data['endpoints'][0]['details']['protocols']
    except:
        protocols = 'NA'

    try:
        vulnBeast = data['endpoints'][0]['details']['vulnBeast']
    except:
        vulnBeast = 'NA'

    try:
        supportsRc4 = data['endpoints'][0]['details']['supportsRc4']
    except:
        supportsRc4 = 'NA'

    try:
        heartbleed = data['endpoints'][0]['details']['heartbleed']
    except:
        heartbleed = 'NA'

    try:
        heartbeat = data['endpoints'][0]['details']['heartbeat']
    except:
        heartbeat = 'NA'

    try:
        openSslCcs = data['endpoints'][0]['details']['openSslCcs']
    except:
        openSslCcs = 'NA'

    try:
        openSSLLuckyMinus20 = data['endpoints'][0]['details']['openSSLLuckyMinus20']
    except:
        openSSLLuckyMinus20 = 'NA'

    try:
        ticketbleed = data['endpoints'][0]['details']['ticketbleed']
    except:
        ticketbleed = 'NA'

    try:
        bleichenbacher = data['endpoints'][0]['details']['bleichenbacher']
    except:
        bleichenbacher = 'NA'

    try:
        zombiePoodle = data['endpoints'][0]['details']['zombiePoodle']
    except:
        zombiePoodle = 'NA'

    try:
        goldenDoodle = data['endpoints'][0]['details']['goldenDoodle']
    except:
        goldenDoodle = 'NA'

    try:
        zeroLengthPaddingOracle = data['endpoints'][0]['details']['zeroLengthPaddingOracle']
    except:
        zeroLengthPaddingOracle = 'NA'

    try:
        sleepingPoodle = data['endpoints'][0]['details']['sleepingPoodle']
    except:
        sleepingPoodle = 'NA'

    try:
        poodle = data['endpoints'][0]['details']['poodle']
    except:
        poodle = 'NA'

    try:
        poodleTls = data['endpoints'][0]['details']['poodleTls']
    except:
        poodleTls = 'NA'

    try:
        fallbackScsv = data['endpoints'][0]['details']['fallbackScsv']
    except:
        fallbackScsv = 'NA'

    try:
        freak = data['endpoints'][0]['details']['freak']
    except:
        freak = 'NA'

    try:
        logjam = data['endpoints'][0]['details']['logjam']
    except:
        logjam = 'NA'

    try:
        drownVulnerable = data['endpoints'][0]['details']['drownVulnerable']
    except:
        drownVulnerable = 'NA'

    csv_data = {
        'host': host,
        'rank': rank,
        'industry': industry,
        'geoLocation': geoLocation,
        'ipAddress': ipAddress,
        'grade': grade,
        'protocols': protocols,
        'vulnBeast': vulnBeast,
        'supportsRc4': supportsRc4,
        'heartbleed': heartbleed,
        'heartbeat': heartbeat,
        'openSslCcs': openSslCcs,
        'openSSLLuckyMinus20': openSSLLuckyMinus20,
        'ticketbleed': ticketbleed,
        'bleichenbacher': bleichenbacher,
        'zombiePoodle': zombiePoodle,
        'goldenDoodle': goldenDoodle,
        'zeroLengthPaddingOracle': zeroLengthPaddingOracle,
        'sleepingPoodle': sleepingPoodle,
        'poodle': poodle,
        'poodleTls': poodleTls,
        'fallbackScsv': fallbackScsv,
        'freak': freak,
        'logjam': logjam,
        'drownVulnerable': drownVulnerable,
    }

    print('SCANNING COMPLETE')
    final = url_rank[1] + ": " + grade
    print(final)
    return csv_data


@click.command()
@click.argument('inputfile')
@click.argument('outputfile')
def main(inputfile, outputfile):
    input_file = open(inputfile, 'r')
    websites = input_file.readlines()
    websites_stripped = list(map(lambda url: url.rstrip(), websites))
    input_file.close()

    output_csv = open(outputfile, 'w')
    writer = csv.DictWriter(output_csv, fieldnames=fieldnames)
    writer.writeheader()
    output_csv.close()

    with concurrent.futures.ThreadPoolExecutor(max_workers=25) as executor:
        future_to_url = {executor.submit(scanning_func, url): url for url in websites_stripped}
        for future in concurrent.futures.as_completed(future_to_url):
            try:
                data = future.result()
                output_csv = open(outputfile, 'a+')
                writer = csv.DictWriter(output_csv, fieldnames=fieldnames)
                writer.writerow(data)
                output_csv.close()
            except Exception as exc:
                print('Exception has been thrown: ' + str(exc))
            else:
                print('RESULT: ' + str(data))


main()
