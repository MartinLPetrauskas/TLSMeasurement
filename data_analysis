#! /usr/bin/env python3
import datetime
import pandas as pd
import json
import math
import logging
import click

logging.basicConfig(level=logging.DEBUG)

COLUMNS = ['host', 'rank', 'industry', 'geoLocation', 'ipAddress', 'grade', 'protocols', 'vulnBeast', 'supportsRc4',
           'heartbleed', 'heartbeat', 'openSslCcs', 'openSSLLuckyMinus20', 'ticketbleed', 'bleichenbacher',
           'zombiePoodle', 'goldenDoodle', 'zeroLengthPaddingOracle', 'sleepingPoodle', 'poodle', 'poodleTls',
           'fallbackScsv', 'freak', 'logjam', 'drownVulnerable']


def all_breakdown(df, output_file, vuln):
    """
    This function performs an entire analysis for a given DataFrame including analyzing the
    overall grade, the SSL/TLS protocols supports, and some calculations on vulnerabilities
    @param df: DataFrame object from CSV file
    @param output_file: file descriptor for output file
    @param vuln: boolean flag if specific vulnerabilities should be put in output file
    @return: None
    """
    overall_grades(df, output_file, vuln)
    tls_support(df, output_file, vuln)
    vulnerability_report(df, output_file, vuln)


def geo_breakdown(df, output_file, vuln):
    """
    This function performs an analysis based on geographic location
    @param df: DataFrame object from CSV file
    @param output_file: file descriptor for the output file
    @param vuln: boolean flag if the specific vulnerability should be put in output file
    @return: None
    """
    with pd.option_context('display.max_rows', None):
        logging.debug('Count of Each Country:')
        logging.debug(str(df.geoLocation.value_counts()))

    dict_of_dfs = {}
    for n, g in df.groupby(df['geoLocation']):
        dict_of_dfs[n] = g

    list_other_countries_df = []
    list_other_countries = []
    for country in dict_of_dfs.keys():
        country_df = dict_of_dfs[country]
        num_rows = country_df.shape[0]
        if num_rows < 50:
            list_other_countries_df.append(country_df)
            list_other_countries.append(country_df['geoLocation'].iloc[0])
        else:
            output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
            output_file.write('GEOLOCATION BREAKDOWN FOR: ' + country + '\n')
            print('GEOLOCATION BREAKDOWN FOR: ' + country)
            all_breakdown(country_df, output_file, vuln)
            output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    other_countries = pd.concat(list_other_countries_df, axis=0, ignore_index=True)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Number of countries in other category: ' + str(len(list_other_countries)) + '\n')
    output_file.write('Countries in other category: ' + "; ".join(list_other_countries) + '\n')
    output_file.write('GEOLOCATION FOR OTHER COUNTRIES:\n')
    print('GEOLOCATION FOR OTHER COUNTRIES:\n')
    all_breakdown(other_countries, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')


def log_breakdown(df, output_file, vuln):
    """
    This function will perform a logarithmic based analysis on the data
    @param df: DataFrame object from the CSV file
    @param output_file: file descriptor of the output file
    @param vuln: boolean flag if specific vulnerabilities should be put in output file
    @return: None
    """
    df1_10 = pd.DataFrame(columns=COLUMNS)
    df11_100 = pd.DataFrame(columns=COLUMNS)
    df101_1000 = pd.DataFrame(columns=COLUMNS)
    df1001_10000 = pd.DataFrame(columns=COLUMNS)

    for index, row in df.iterrows():
        if row['rank'] < 11:
            df1_10 = df1_10.append(row, ignore_index=True)
            continue
        if row['rank'] < 101:
            df11_100 = df11_100.append(row, ignore_index=True)
            continue
        if row['rank'] < 1001:
            df101_1000 = df101_1000.append(row, ignore_index=True)
            continue
        if row['rank'] < 10000:
            df1001_10000 = df1001_10000.append(row, ignore_index=True)
            continue

    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('RANKS 1-10:\n')
    all_breakdown(df1_10, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('RANKS 11-100:\n')
    all_breakdown(df11_100, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('RANKS 101-1000:\n')
    all_breakdown(df101_1000, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('RANKS 1001-10000:\n')
    all_breakdown(df1001_10000, output_file, vuln)


def industry_breakdown(df, output_file, vuln):
    """
    This function will perform an industry based analysis on the data
    @param df: DataFrame object from the CSV file
    @param output_file: file descriptor of the output file
    @param vuln: boolean flag if specific vulnerabilities should be put in output file
    @return: None
    """
    with pd.option_context('display.max_rows', None):
        logging.debug('Count of each industry: ')
        logging.debug(str(df.industry.value_counts()))
    dict_of_dfs = {}
    for n, g in df.groupby(df['industry']):
        dict_of_dfs[n] = g

    media_entertainment_df = pd.concat([dict_of_dfs['media'], dict_of_dfs['entertainment']], axis=0, ignore_index=True)
    technology_df = dict_of_dfs['technology']
    education_df = dict_of_dfs['education']
    prof_services_df = pd.concat([dict_of_dfs['professional services'], dict_of_dfs['courier service']], axis=0,
                                 ignore_index=True)
    ecommerce_retail_df = pd.concat([dict_of_dfs['ecommerce'], dict_of_dfs['retail']], axis=0, ignore_index=True)
    financial_df = dict_of_dfs['financial']
    government_public_services_df = pd.concat([dict_of_dfs['government'], dict_of_dfs['public service']], axis=0,
                                              ignore_index=True)
    travel_hospitality_df = pd.concat([dict_of_dfs['hospitality'], dict_of_dfs['travel']], axis=0, ignore_index=True)
    healthcare_df = dict_of_dfs['healthcare']
    automotive_df = dict_of_dfs['automobile']
    industrial_df = dict_of_dfs['industrial']
    real_estate_df = dict_of_dfs['real estate']
    telcom_df = dict_of_dfs['telcom']

    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Media/Entertainment Industry Analysis:\n')
    all_breakdown(media_entertainment_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Technology Industry Analysis:\n')
    all_breakdown(technology_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Education Industry Analysis:\n')
    all_breakdown(education_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Professional Services Industry Analysis:\n')
    all_breakdown(prof_services_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('E-commerce & Retail Industry Analysis:\n')
    all_breakdown(ecommerce_retail_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Financial Industry Analysis:\n')
    all_breakdown(financial_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Government & Public Services Industry Analysis:\n')
    all_breakdown(government_public_services_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Travel & Hospitality Industry Analysis:\n')
    all_breakdown(travel_hospitality_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('HealthCare Industry Analysis:\n')
    all_breakdown(healthcare_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Automotive Industry Analysis:\n')
    all_breakdown(automotive_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Industrial Industry Analysis:\n')
    all_breakdown(industrial_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Real Estate Industry Analysis:\n')
    all_breakdown(real_estate_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Telcom Industry Analysis:\n')
    all_breakdown(telcom_df, output_file, vuln)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')


def overall_grades(df, output_file, vuln):
    """
    This function will return the number of grades (A+, A, A-, B, ..., F)
    @note appends grades of F to a text file
    @param df: DataFrame object from CSV file
    @param output_file: file descriptor of output file
    """
    grade_value_counts = str(df.grade.value_counts(normalize=True))
    num_rows = df.shape[0]
    output_file.write('Number of URLs Analyzed: ' + str(num_rows) + '\n')
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Overall Grades (Percentages out of 1.0):\n' +
                      grade_value_counts[:grade_value_counts.rfind('\n')] + '\n')
    if vuln:
        for index, row in df.iterrows():
            if row.grade == 'F':
                output = 'Website: ' + row.host + ', Grade: ' + row.grade + '\n'
                output_file.write(output)
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')


def tls_support(df, output_file, vuln):
    """
    This function will parse through the various SSL/TLS protocols that are supported
    @note: SSL v2.0, SSL v3.0, TLS v1.0, TLS v1.1, TLS v1.2, TLS v1.3 are the supported protocols
    @param df:  DataFrame object from CSV file
    @param output_file: file descriptor of the output file
    @return: None
    """
    num_rows = df.shape[0]
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('SSL/TLS Protocols Supported:\n')
    # overall tls support count
    # id mappings:
    # 512 -> SSL v2.0
    # 768 -> SSL v3.0
    # 769 -> TLS v1.0
    # 770 -> TLS v1.1
    # 771 -> TLS v1.2
    # 772 -> TLS v1.3
    tls_support_stats = {
        'SSL v2.0': 0,
        'SSL v3.0': 0,
        'TLS v1.0': 0,
        'TLS v1.1': 0,
        'TLS v1.2': 0,
        'TLS v1.3': 0,
    }
    ssl_support_num = tls_overall_num = tls_bad_num = max_ssl2 = max_ssl3 = max_tls_10 = max_tls_11 = max_tls_12 = \
        max_tls_13 = 0
    for index, row in df.iterrows():
        protocols = row.protocols
        try:
            protocols_json = protocols.replace("\'", "\"")
        except Exception as exc:
            # NOTE: exceptions will be thrown if the protocols is a nan (i.e. for those sites that couldn't be scanned)
            logging.debug(exc)
            logging.debug(protocols)
        protocols_list = json.loads(protocols_json)
        # This block of if statements gets a combined count for SSL/TLS
        # broken into all SSL, all TLS, and TLS v1.0/v1.1
        ids = [protocol['id'] for protocol in protocols_list]
        if 512 in ids or 768 in ids:
            ssl_support_num += 1
        if 769 in ids or 770 in ids:
            tls_bad_num += 1
        if 769 in ids or 770 in ids or 771 in ids or 772 in ids:
            tls_overall_num += 1
        # This block of if statements calculates the max protocol supported
        if len(ids) > 0:
            if max(ids) == 512:
                max_ssl2 += 1
                if vuln:
                    output_file.write('Website: ' + row.host + ', at best only supports SSL v2.0\n')
            if max(ids) == 768:
                max_ssl3 += 1
                if vuln:
                    output_file.write('Website: ' + row.host + ', at best only supports SSL v2.0\n')
            if max(ids) == 769:
                max_tls_10 += 1
                if vuln:
                    output_file.write('Website: ' + row.host + ', at best only supports TLS v1.0\n')
            if max(ids) == 770:
                max_tls_11 += 1
                if vuln:
                    output_file.write('Website: ' + row.host + ', at best only supports TLS v1.1\n')
            if max(ids) == 771:
                max_tls_12 += 1
            if max(ids) == 772:
                max_tls_13 += 1
        for protocol in protocols_list:
            if protocol['id'] == 512:
                tls_support_stats['SSL v2.0'] += 1
                if vuln:
                    output = 'Website: ' + row.host + ', supports SSL v2.0\n'
                    output_file.write(output)
                continue
            if protocol['id'] == 768:
                tls_support_stats['SSL v3.0'] += 1
                if vuln:
                    output = 'Website: ' + row.host + ', supports SSL v3.0\n'
                    output_file.write(output)
                continue
            if protocol['id'] == 769:
                tls_support_stats['TLS v1.0'] += 1
                continue
            if protocol['id'] == 770:
                tls_support_stats['TLS v1.1'] += 1
                continue
            if protocol['id'] == 771:
                tls_support_stats['TLS v1.2'] += 1
                continue
            if protocol['id'] == 772:
                tls_support_stats['TLS v1.3'] += 1
                continue
            else:
                print('UNKNOWN PROTOCOL ID: ')
                print(protocol['id'])
    output_file.write('Number of sites that support SSL: ' + str(ssl_support_num) + ' ('
                      + str(round(ssl_support_num / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support TLS v1.0 or v1.1: ' + str(tls_bad_num) + ' ('
                      + str(round(tls_bad_num / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support TLS: ' + str(tls_overall_num) + ' (' +
                      str(round(tls_overall_num / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support max SSL v2.0: ' + str(max_ssl2) + ' (' +
                      str(round(max_ssl2 / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support max SSL v3.0: ' + str(max_ssl3) + ' (' +
                      str(round(max_ssl3 / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support max TLS v1.0: ' + str(max_tls_10) + ' (' +
                      str(round(max_tls_10 / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support max TLS v1.1: ' + str(max_tls_11) + ' (' +
                      str(round(max_tls_11 / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support max TLS v1.2: ' + str(max_tls_12) + ' (' +
                      str(round(max_tls_12 / num_rows * 100, 4)) + '%)\n')
    output_file.write('Number of sites that support max TLS v1.3: ' + str(max_tls_13) + ' (' +
                      str(round(max_tls_13 / num_rows * 100, 4)) + '%)\n')
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')


def vulnerability_count(row):
    """
    This function will assist in determining the count of sites which are vulnerable to
    certain known vulnerabilities
    @param row: row from a DataFram
    @return: True if at least one vulnerability is present, False otherwise
    """
    if (row.heartbleed
            or row.openSslCcs == 2
            or row.openSslCcs == 3
            or row.ticketbleed == 2
            or row.openSSLLuckyMinus20 == 2
            or row.bleichenbacher == 2 or row.bleichenbacher == 3
            or row.zombiePoodle == 2 or row.zombiePoodle == 3
            or row.goldenDoodle == 4 or row.goldenDoodle == 5
            or row.zeroLengthPaddingOracle == 6 or row.zeroLengthPaddingOracle == 7
            or row.sleepingPoodle == 10 or row.sleepingPoodle == 11
            or row.poodle
            or row.poodleTls == 2
            or row.fallbackScsv is False
            or row.freak
            or row.logjam
            or row.drownVulnerable
    ):
        return True


def vulnerability_percentage(vuln, total):
    return str(round((vuln / total) * 100, 5))


def vulnerability_report(df, output_file, vuln):
    """
    This function will return all the statistics for the various vulnerabilities recorded
    @param df:  DataFrame object from the CSV file
    @param output_file: file descriptor of the output file
    @return: None
    """
    # NOTE: BEAST vulnerability commented out since SSL Labs API results are for the client-side vulnerability
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Vulnerability Report:\n')

    total_sites = df.shape[0]
    # first iterate through all the sites and add vulnerable sites to the output file
    num_vulnerable_sites = 0
    # count the number sites for each vulnerability
    rc4_support_num = heartbleed_num = opensslccs_num = opensslluckminus20_num = ticketbleed_num = bleichenbacher_num \
        = zombiepoodle_num = goldendoodle_num = zerolengthpaddingoracle_num = sleepingpoddle_num = poodle_num \
        = poodletls_num = fallback_num = freak_num = logjam_num = drown_num = 0
    if vuln:
        for index, row in df.iterrows():
            if vulnerability_count(row):
                num_vulnerable_sites += 1
            # RC4 support
            if row.supportsRc4 is True:
                rc4_support_num += 1
                output = 'Website: ' + row.host + ' supports at least one RC4 cipher suite\n'
                output_file.write(output)
            # heartbleed vulnerability
            if row.heartbleed is True:
                heartbleed_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to the Heartbleed attack\n'
                output_file.write(output)
            # opensslccs vulnerability (CVE-2014-0224)
            if row.openSslCcs == 2 or row.openSslCcs == 3:
                opensslccs_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to openSSLccs (CVE-2014-0224)\n'
                output_file.write(output)
            # opensslluckyminus20 vulnerability (CVE-2016-2107)
            if row.openSSLLuckyMinus20 == 2:
                opensslluckminus20_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to openSSLLuckyMinus20 (CVE-2016-2107)\n'
                output_file.write(output)
            # ticketbleed vulnerability (CVE-2016-9244)
            if row.ticketbleed == 2:
                ticketbleed_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to ticketbleed (CVE-2016-9244)\n'
                output_file.write(output)
            # The following is a debug for getting sites which returned a 3 for Ticketbleed
            # TODO: remove once the issue has been resolved with a couple sites returning a 3
            if row.ticketbleed == 3:
                output = 'TICKETBLEED DEBUG: ' + row.host + '\n'
                print(output)
            # bleichenbacher vulnerability (ROBOT attack)
            if row.bleichenbacher == 2 or row.bleichenbacher == 3:
                bleichenbacher_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to ROBOT attack\n'
                output_file.write(output)
            # zombiePoodle attack
            if row.zombiePoodle == 2 or row.zombiePoodle == 3:
                zombiepoodle_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to ZombiePoodle attack\n'
                output_file.write(output)
            # goldenDoodle attack
            if row.goldenDoodle == 4 or row.goldenDoodle == 5:
                goldendoodle_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to GoldenDoodle attack\n'
                output_file.write(output)
            # zeroLengthPaddingOracle (CVE-2019-1559)
            if row.zeroLengthPaddingOracle == 6 or row.zeroLengthPaddingOracle == 7:
                zerolengthpaddingoracle_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to 0-lengthPaddingOracle attack\n'
                output_file.write(output)
            # sleepingPoodle attack
            if row.sleepingPoodle == 10 or row.sleepingPoodle == 11:
                sleepingpoddle_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to SleepingPoodle attack\n'
                output_file.write(output)
            # poodle attack
            if row.poodle is True:
                poodle_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to Poodle attack\n'
                output_file.write(output)
            # poodleTls
            if row.poodleTls == 2:
                poodletls_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to PoodleTLS attack\n'
                output_file.write(output)
            # fallbackScsv attack
            if row.fallbackScsv is False:
                fallback_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to downgrade attack\n'
                output_file.write(output)
            # freak vulnerability
            if row.freak is True:
                freak_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to FREAK attack\n'
                output_file.write(output)
            # logjam vulnerability
            if row.logjam is True:
                logjam_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to logjam attack\n'
                output_file.write(output)
            # DROWN vulnerability
            if row.drownVulnerable is True:
                drown_num += 1
                output = 'Website: ' + row.host + ' is vulnerable to DROWN attack\n'
                output_file.write(output)
        output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
        output_file.write('Number of vulnerable sites: ' + str(num_vulnerable_sites) + '\n')
        output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')
    output_file.write('Vulnerability Statistics:\n')
    # output_file.write(str(df.vulnBeast.value_counts()) + '\n\n')
    output_file.write(str(df.supportsRc4.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(rc4_support_num, total_sites) + '\n\n')
    output_file.write(str(df.heartbleed.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(heartbleed_num, total_sites) + '\n\n')
    output_file.write(str(df.heartbeat.value_counts()) + '\n\n')
    output_file.write(str(df.openSslCcs.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(opensslccs_num, total_sites) + '\n\n')
    output_file.write(str(df.openSSLLuckyMinus20.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(opensslluckminus20_num, total_sites) + '\n\n')
    output_file.write(str(df.ticketbleed.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(ticketbleed_num, total_sites) + '\n\n')
    output_file.write(str(df.bleichenbacher.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(bleichenbacher_num, total_sites) + '\n\n')
    output_file.write(str(df.zombiePoodle.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(zombiepoodle_num, total_sites) + '\n\n')
    output_file.write(str(df.goldenDoodle.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(goldendoodle_num, total_sites) + '\n\n')
    output_file.write(str(df.zeroLengthPaddingOracle.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(zerolengthpaddingoracle_num, total_sites) + '\n\n')
    output_file.write(str(df.sleepingPoodle.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(sleepingpoddle_num, total_sites) + '\n\n')
    output_file.write(str(df.poodle.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(poodle_num, total_sites) + '\n\n')
    output_file.write(str(df.poodleTls.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(poodletls_num, total_sites) + '\n\n')
    output_file.write(str(df.fallbackScsv.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(fallback_num, total_sites) + '\n\n')
    output_file.write(str(df.freak.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(freak_num, total_sites) + '\n\n')
    output_file.write(str(df.logjam.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(logjam_num, total_sites) + '\n\n')
    output_file.write(str(df.drownVulnerable.value_counts()) + '\nPercentage Vulnerable: ' + vulnerability_percentage(drown_num, total_sites) + '\n\n')
    output_file.write('++++++++++++++++++++++++++++++++++++++++++\n')


@click.command()
@click.argument('csvfile')
@click.option('--output', default='basic-report.txt', help='Name of output file for analysis')
@click.option('--all', is_flag=True, help='Analyze all TLS results with no breakdown')
@click.option('--industry', is_flag=True, help='Analyze the TLS results  via industry')
@click.option('--geo', is_flag=True, help='Analyze the TLS results via geo-location')
@click.option('--log', is_flag=True, help='Analyze the TLS results via logarithmic ranking')
@click.option('--vuln', is_flag=True, help='Add vulnerable websites to output file')
def main(csvfile, output, all, industry, geo, log, vuln):
    # grab the filename from click and read it into a DataFrame
    df = pd.read_csv(csvfile)
    # now we take out the null results from the data set
    # refined_df = pd.DataFrame(columns=COLUMNS)
    df = df[df.grade.notnull()]
    df = df[df.geoLocation.notnull()]
    df = df[df.ipAddress.notnull()]
    df = df[df.protocols.notnull()]
    # write some basic information to output file
    output_file = open(output, 'w+')
    output_file.write('Results for TLS Analysis:\n')
    output_file.write('Analysis run at: ' + str(datetime.datetime.now()) + '\n')
    if all is True:
        output_file.write('==========================================\n')
        output_file.write('Regular Analysis\n')
        all_breakdown(df, output_file, vuln)
        output_file.write('==========================================\n')
    if industry is True:
        output_file.write('==========================================\n')
        output_file.write('Industry Analysis\n')
        industry_breakdown(df, output_file, vuln)
        output_file.write('==========================================\n')
    if geo is True:
        output_file.write('==========================================\n')
        output_file.write('Geolocation Analysis\n')
        geo_breakdown(df, output_file, vuln)
        output_file.write('==========================================\n')
    if log is True:
        output_file.write('==========================================\n')
        output_file.write('Logarithmic Analysis\n')
        log_breakdown(df, output_file, vuln)
        output_file.write('==========================================\n')
    output_file.close()


main()
